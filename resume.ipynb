{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf6f8e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API keys from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "05b86803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "# Load and read PDF resume\n",
    "loader = PyMuPDFLoader(\"C://Users//HARSHIT//Downloads//Harshit_Resume.pdf\")\n",
    "doc = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "df857ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-25T13:11:13+00:00', 'source': 'C://Users//HARSHIT//Downloads//Harshit_Resume.pdf', 'file_path': 'C://Users//HARSHIT//Downloads//Harshit_Resume.pdf', 'total_pages': 1, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-25T13:11:13+00:00', 'trapped': '', 'modDate': 'D:20250525131113Z', 'creationDate': 'D:20250525131113Z', 'page': 0}, page_content='Harshit Khatta\\nharshitkhatta7@gmail.com | +91 62807 33152 | LinkedIn | GitHub: HarshitKhatta\\nExperience\\nData Analyst\\nDec 2024 - Feb 2025\\nErnst & Young (EY)\\nNoida, India\\n‚Ä¢ Automated data pipelines by building Python scripts for data cleaning, transformation, and validation\\nacross multiple sources, improving data quality and reducing processing time by 30%\\n‚Ä¢ Designed and deployed Alteryx ETL workflows, reducing manual data handling time by 40% and\\nincreasing reporting efficiency for weekly business performance reviews\\n‚Ä¢ Optimized SQL queries on datasets exceeding 5M+ records, accelerating dashboard refresh rates by 25% and\\nenabling faster decision-making across cross-functional teams\\nData Scientist Trainee\\nJan 2024 - Jun 2024\\nSunfocus Solutions Pvt. Ltd.\\nMohali, India\\n‚Ä¢ Automated data workflows using Python, processing over 500,000 records with Pandas and NumPy,\\nimproving runtime efficiency by 20% through optimized scripting\\n‚Ä¢ Performed comprehensive EDA and created 50+ interactive visualizations, contributing to a 30%\\nimprovement in internal data-driven decision-making\\n‚Ä¢ Developed ML pipelines for news classification and sentiment analysis using TF-IDF and Logistic\\nRegression, achieving 85%+ accuracy in PoC environments\\nProjects\\nSleeping Disorder Analysis | Pandas, NumPy, Sklearn, Seaborn, Streamlit [Link]\\nMar 2024 - May 2024\\n‚Ä¢ Analyzed over 10,000+ medical records to identify key predictors of sleep disorders using ML and\\nstatistical techniques, including EDA with 50+ visualizations highlighting links between lifestyle and sleep\\nquality\\n‚Ä¢ Built and tuned Random Forest and SVM models, achieving 15% boost in detection accuracy and improving\\nmodel generalization by 20%\\n‚Ä¢ Serialized the top-performing model using Pickle and prepared with Streamlit, enabling early diagnosis through a\\nlightweight predictive web app\\nIMDB Sentiment Classification | TensorFlow, Pandas, NumPy, Streamlit [Link]\\nNov 2024 - Jan 2025\\n‚Ä¢ Built and trained a SimpleRNN model using Keras on the IMDB movie review dataset, achieving 88%\\ntest accuracy for binary sentiment classification\\n‚Ä¢ Preprocessed 25,000+ reviews using text vectorization (One-Hot Encoding) and sequence padding,\\nensuring robust input structure for neural network training\\n‚Ä¢ Integrated with TensorBoard for model visualization and developed a user-friendly Streamlit interface for\\nreal-time predictions\\n‚Ä¢ Saved and created the model using Pickle to enable reproducibility and ease of production integration\\nTechnical Skills\\nLanguages: Python (OOPs, scripting), SQL (MySQL, PostgreSQL), C/C++\\nLibraries & Frameworks: Pandas, NumPy, Matplotlib, Seaborn, Plotly, Scikit-learn, TensorFlow, Keras, Streamlit,\\nSelenium\\nMachine Learning: Linear & Logistic Regression, Decision Trees, Random Forest, SVM, KNN, Naive Bayes,\\nClustering (K-Means, Hierarchical), PCA, NLP\\nTools & Platforms: VS Code, PyCharm, IntelliJ, Alteryx, Tableau, MS Excel (Advanced), TensorBoard, RESTful\\nAPIs\\nDatabases: MongoDB, SQLite, Oracle\\nConcepts: EDA, Feature Engineering, Data Cleaning, Model Evaluation, ETL\\nVersion Control & Utilities: Git, GitHub, Pickle, Scikeras\\nEducation\\nPunjabi University\\nPatiala, India\\nMaster of Computer Applications | 8.3 CGPA\\nSep 2022 - May 2024\\nArya College (Affiliated by P.U.)\\nLudhiana, India\\nBachelor of Computer Applications | 8.2 CGPA\\nAug 2019 - Apr 2022')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "68c8d214",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "split_docs = text_splitter.split_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "edebd69c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-25T13:11:13+00:00', 'source': 'C://Users//HARSHIT//Downloads//Harshit_Resume.pdf', 'file_path': 'C://Users//HARSHIT//Downloads//Harshit_Resume.pdf', 'total_pages': 1, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-25T13:11:13+00:00', 'trapped': '', 'modDate': 'D:20250525131113Z', 'creationDate': 'D:20250525131113Z', 'page': 0}, page_content='Harshit Khatta\\nharshitkhatta7@gmail.com | +91 62807 33152 | LinkedIn | GitHub: HarshitKhatta\\nExperience\\nData Analyst\\nDec 2024 - Feb 2025\\nErnst & Young (EY)\\nNoida, India\\n‚Ä¢ Automated data pipelines by building Python scripts for data cleaning, transformation, and validation\\nacross multiple sources, improving data quality and reducing processing time by 30%\\n‚Ä¢ Designed and deployed Alteryx ETL workflows, reducing manual data handling time by 40% and'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-25T13:11:13+00:00', 'source': 'C://Users//HARSHIT//Downloads//Harshit_Resume.pdf', 'file_path': 'C://Users//HARSHIT//Downloads//Harshit_Resume.pdf', 'total_pages': 1, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-25T13:11:13+00:00', 'trapped': '', 'modDate': 'D:20250525131113Z', 'creationDate': 'D:20250525131113Z', 'page': 0}, page_content='increasing reporting efficiency for weekly business performance reviews\\n‚Ä¢ Optimized SQL queries on datasets exceeding 5M+ records, accelerating dashboard refresh rates by 25% and\\nenabling faster decision-making across cross-functional teams\\nData Scientist Trainee\\nJan 2024 - Jun 2024\\nSunfocus Solutions Pvt. Ltd.\\nMohali, India\\n‚Ä¢ Automated data workflows using Python, processing over 500,000 records with Pandas and NumPy,\\nimproving runtime efficiency by 20% through optimized scripting'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-25T13:11:13+00:00', 'source': 'C://Users//HARSHIT//Downloads//Harshit_Resume.pdf', 'file_path': 'C://Users//HARSHIT//Downloads//Harshit_Resume.pdf', 'total_pages': 1, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-25T13:11:13+00:00', 'trapped': '', 'modDate': 'D:20250525131113Z', 'creationDate': 'D:20250525131113Z', 'page': 0}, page_content='‚Ä¢ Performed comprehensive EDA and created 50+ interactive visualizations, contributing to a 30%\\nimprovement in internal data-driven decision-making\\n‚Ä¢ Developed ML pipelines for news classification and sentiment analysis using TF-IDF and Logistic\\nRegression, achieving 85%+ accuracy in PoC environments\\nProjects\\nSleeping Disorder Analysis | Pandas, NumPy, Sklearn, Seaborn, Streamlit [Link]\\nMar 2024 - May 2024'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-25T13:11:13+00:00', 'source': 'C://Users//HARSHIT//Downloads//Harshit_Resume.pdf', 'file_path': 'C://Users//HARSHIT//Downloads//Harshit_Resume.pdf', 'total_pages': 1, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-25T13:11:13+00:00', 'trapped': '', 'modDate': 'D:20250525131113Z', 'creationDate': 'D:20250525131113Z', 'page': 0}, page_content='Mar 2024 - May 2024\\n‚Ä¢ Analyzed over 10,000+ medical records to identify key predictors of sleep disorders using ML and\\nstatistical techniques, including EDA with 50+ visualizations highlighting links between lifestyle and sleep\\nquality\\n‚Ä¢ Built and tuned Random Forest and SVM models, achieving 15% boost in detection accuracy and improving\\nmodel generalization by 20%\\n‚Ä¢ Serialized the top-performing model using Pickle and prepared with Streamlit, enabling early diagnosis through a'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-25T13:11:13+00:00', 'source': 'C://Users//HARSHIT//Downloads//Harshit_Resume.pdf', 'file_path': 'C://Users//HARSHIT//Downloads//Harshit_Resume.pdf', 'total_pages': 1, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-25T13:11:13+00:00', 'trapped': '', 'modDate': 'D:20250525131113Z', 'creationDate': 'D:20250525131113Z', 'page': 0}, page_content='lightweight predictive web app\\nIMDB Sentiment Classification | TensorFlow, Pandas, NumPy, Streamlit [Link]\\nNov 2024 - Jan 2025\\n‚Ä¢ Built and trained a SimpleRNN model using Keras on the IMDB movie review dataset, achieving 88%\\ntest accuracy for binary sentiment classification\\n‚Ä¢ Preprocessed 25,000+ reviews using text vectorization (One-Hot Encoding) and sequence padding,\\nensuring robust input structure for neural network training'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-25T13:11:13+00:00', 'source': 'C://Users//HARSHIT//Downloads//Harshit_Resume.pdf', 'file_path': 'C://Users//HARSHIT//Downloads//Harshit_Resume.pdf', 'total_pages': 1, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-25T13:11:13+00:00', 'trapped': '', 'modDate': 'D:20250525131113Z', 'creationDate': 'D:20250525131113Z', 'page': 0}, page_content='‚Ä¢ Integrated with TensorBoard for model visualization and developed a user-friendly Streamlit interface for\\nreal-time predictions\\n‚Ä¢ Saved and created the model using Pickle to enable reproducibility and ease of production integration\\nTechnical Skills\\nLanguages: Python (OOPs, scripting), SQL (MySQL, PostgreSQL), C/C++\\nLibraries & Frameworks: Pandas, NumPy, Matplotlib, Seaborn, Plotly, Scikit-learn, TensorFlow, Keras, Streamlit,\\nSelenium'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-25T13:11:13+00:00', 'source': 'C://Users//HARSHIT//Downloads//Harshit_Resume.pdf', 'file_path': 'C://Users//HARSHIT//Downloads//Harshit_Resume.pdf', 'total_pages': 1, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-25T13:11:13+00:00', 'trapped': '', 'modDate': 'D:20250525131113Z', 'creationDate': 'D:20250525131113Z', 'page': 0}, page_content='Selenium\\nMachine Learning: Linear & Logistic Regression, Decision Trees, Random Forest, SVM, KNN, Naive Bayes,\\nClustering (K-Means, Hierarchical), PCA, NLP\\nTools & Platforms: VS Code, PyCharm, IntelliJ, Alteryx, Tableau, MS Excel (Advanced), TensorBoard, RESTful\\nAPIs\\nDatabases: MongoDB, SQLite, Oracle\\nConcepts: EDA, Feature Engineering, Data Cleaning, Model Evaluation, ETL\\nVersion Control & Utilities: Git, GitHub, Pickle, Scikeras\\nEducation\\nPunjabi University\\nPatiala, India'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-25T13:11:13+00:00', 'source': 'C://Users//HARSHIT//Downloads//Harshit_Resume.pdf', 'file_path': 'C://Users//HARSHIT//Downloads//Harshit_Resume.pdf', 'total_pages': 1, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-25T13:11:13+00:00', 'trapped': '', 'modDate': 'D:20250525131113Z', 'creationDate': 'D:20250525131113Z', 'page': 0}, page_content='Education\\nPunjabi University\\nPatiala, India\\nMaster of Computer Applications | 8.3 CGPA\\nSep 2022 - May 2024\\nArya College (Affiliated by P.U.)\\nLudhiana, India\\nBachelor of Computer Applications | 8.2 CGPA\\nAug 2019 - Apr 2022')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5f3a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "embedding = OllamaEmbeddings(model=\"nomic-embed-text\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "024741f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vectorstore = FAISS.from_documents(split_docs, embedding=embedding)\n",
    "retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6fb6ffaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ 6. Define Job Description\n",
    "job_description = \"\"\"\n",
    "We are looking for a Python developer with strong experience in machine learning, \n",
    "NLP, Pandas, and Scikit-learn. Familiarity with LLM tools, good communication skills, and \n",
    "a strong understanding of data pipelines is preferred.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81dc67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\",\n",
    "            \"You are a professional resume evaluator.\\n\"\n",
    "            \"You are a recruitment consultant or HR expert.\\n\"\n",
    "            \"Given the candidate's resume and job description, evaluate the candidate's fit for the role.\\n\"\n",
    "            \"List strengths, weaknesses, improvement suggestions, top skills, missing skills, and give a fit score out of 100.\\n\"\n",
    "            \"Be concise and clear.\\n\"\n",
    "            \"Resume:\\n\"\n",
    "            \"{context}\\n\\n\"\n",
    "            \"Job Description:\\n\" + job_description),\n",
    "            (\"human\", \"{input}\")\n",
    "        ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "77e47661",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e39e2ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(\n",
    "    model=\"gemma3:1b\",)\n",
    "\n",
    "doc_chain=create_stuff_documents_chain(llm,prompt)\n",
    "retrieval_chain = create_retrieval_chain(retriever=retriever, combine_docs_chain=doc_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ed55eaf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Evaluation Result:\n",
      "\n",
      "Okay, let‚Äôs break down this candidate‚Äôs resume and determine a fit score.\n",
      "\n",
      "**Overall Fit Score: 85/100**\n",
      "\n",
      "**Strengths:**\n",
      "\n",
      "*   **Strong Machine Learning Focus:** The resume directly highlights experience with several key ML techniques: Linear & Logistic Regression, Decision Trees, Random Forest, SVM, KNN, Naive Bayes, and more. This is *critical* for the job description.\n",
      "*   **NLP Expertise:** The experience with RNNs, sentiment classification (IMDB), text vectorization, and Streamlit demonstrates a solid understanding of Natural Language Processing.\n",
      "*   **Data Engineering Skills:**  The experience with data pipelines, ETL workflows, and database interaction (MongoDB, SQLite, Oracle) showcases practical data management skills ‚Äì crucial for a developer role.\n",
      "*   **Tools & Technologies:**  The inclusion of TensorFlow, Keras, Scikit-learn, Pandas, NumPy, Matplotlib, Seaborn, Plotly, Git, GitHub, and Alteryx are all highly relevant to the job.\n",
      "*   **Experience with Streamlit:** Utilizing Streamlit for real-time predictions is a valuable addition and demonstrates a good understanding of front-end development and visualization.\n",
      "*   **Education:** Punjabi University provides a foundational technical education in a relevant field (Machine Learning).\n",
      "\n",
      "**Weaknesses:**\n",
      "\n",
      "*   **Limited LLM Experience:**  The job description emphasizes LLM tools. While the resume touches on it, there's no specific mention of experience with LLMs or models (e.g., GPT-3, BERT, etc.). This is a significant gap.\n",
      "*   **Lack of Specific Project Details:** The resume is somewhat sparse ‚Äì ‚ÄúBuilt and trained a SimpleRNN model‚Ä¶‚Äù is good, but lacks detail about the problem, features used, and the model‚Äôs performance. It's a little generic.\n",
      "*   **Missing SQL Depth:** While SQL is mentioned, the detail of the SQL work (creating models) doesn't show depth of understanding of database design and management.\n",
      "\n",
      "**Improvement Suggestions:**\n",
      "\n",
      "*   **Highlight LLM Experience:**  The candidate *needs* to add a specific example of using or working with LLMs. This could be a brief description of a project or a statement about wanting to learn.\n",
      "*   **Expand Data Pipeline Details:** Provide more detail about the data cleaning and validation steps. Quantify the time savings achieved (e.g., \"reduced processing time by 30%\").\n",
      "*   **Showcase Model Evaluation:**  Include a brief description of the evaluation metrics used (e.g., accuracy, precision, recall, F1-score) and how the model was evaluated.\n",
      "*   **Expand on Streamlit:** Mention the type of features used to achieve real-time predictions or any specific UI design choices.\n",
      "\n",
      "**Top Skills:**\n",
      "\n",
      "1.  **Machine Learning:** (Critical)\n",
      "2.  **Python:** (Essential)\n",
      "3.  **Pandas & NumPy:** (Data Manipulation)\n",
      "4.  **Scikit-learn:** (Machine Learning Library)\n",
      "5.  **TensorFlow/Keras:** (Deep Learning)\n",
      "6.  **SQL:** (Database Management)\n",
      "7.  **Streamlit:** (Front-end Development)\n",
      "8.  **Data Pipelines & ETL:** (Data Engineering)\n",
      "9.  **NLP:** (Relevant)\n",
      "10. **Git/GitHub:** (Version Control)\n",
      "\n",
      "**Missing Skills:**\n",
      "\n",
      "*   **LLM Specific Knowledge:** No mention of experience with LLMs.\n",
      "*   **Cloud Computing:** (If the job involves deploying models).\n",
      "\n",
      "**Fit Score Rationale:**\n",
      "\n",
      "The resume is a strong starting point. The candidate *demonstrates* the skills the job description requires. The main area for improvement is to explicitly address the LLM aspect.  The 85/100 score reflects a solid fit, but with a targeted focus on the LLM component.  It's a good candidate, but there‚Äôs room to significantly boost their value by adding more concrete evidence of their ML expertise.\n",
      "\n",
      "Would you like me to refine this evaluation further, perhaps by focusing on specific aspects or providing more detailed examples of the candidate's skills?\n"
     ]
    }
   ],
   "source": [
    "# job_description = \"\"\"\n",
    "# We are hiring a Python developer with strong experience in machine learning, Pandas, Scikit-learn, and NLP. Excellent communication is a plus.\n",
    "# \"\"\"\n",
    "\n",
    "query = \"Evaluate the resume based on the job description above.\"\n",
    "response = retrieval_chain.invoke({\"input\": query})\n",
    "\n",
    "print(\"\\nüìù Evaluation Result:\\n\")\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3553239e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Langchan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
